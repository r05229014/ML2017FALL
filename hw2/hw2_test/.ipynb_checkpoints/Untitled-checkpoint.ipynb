{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "with open('../data/X_train') as f:\n",
    "    row = csv.reader(f, delimiter =\",\")\n",
    "    next(row,None)\n",
    "    for r in row:\n",
    "        X.append(list(map(float,r)))\n",
    "        \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "with open('../data/Y_train') as f:\n",
    "    row = csv.reader(f, delimiter =\",\")\n",
    "    next(row,None)\n",
    "    for r in row:\n",
    "        y.append(list(map(float,r)))\n",
    "        \n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ericakcc/anaconda3/lib/python3.6/site-packages/Keras-2.0.8-py3.6.egg/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26048 samples, validate on 6513 samples\n",
      "Epoch 1/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.4462 - acc: 0.7591 - val_loss: 0.3658 - val_acc: 0.8392\n",
      "Epoch 2/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.3383 - acc: 0.8477 - val_loss: 0.3342 - val_acc: 0.8469\n",
      "Epoch 3/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.3130 - acc: 0.8555 - val_loss: 0.3236 - val_acc: 0.8491\n",
      "Epoch 4/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.3035 - acc: 0.8589 - val_loss: 0.3210 - val_acc: 0.8526\n",
      "Epoch 5/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2976 - acc: 0.8627 - val_loss: 0.3216 - val_acc: 0.8521\n",
      "Epoch 6/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2932 - acc: 0.8654 - val_loss: 0.3212 - val_acc: 0.8511\n",
      "Epoch 7/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2912 - acc: 0.8658 - val_loss: 0.3225 - val_acc: 0.8508\n",
      "Epoch 8/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2869 - acc: 0.8688 - val_loss: 0.3241 - val_acc: 0.8535\n",
      "Epoch 9/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2851 - acc: 0.8688 - val_loss: 0.3220 - val_acc: 0.8531\n",
      "Epoch 10/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2825 - acc: 0.8695 - val_loss: 0.3301 - val_acc: 0.8520\n",
      "Epoch 11/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2801 - acc: 0.8711 - val_loss: 0.3260 - val_acc: 0.8535\n",
      "Epoch 12/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2783 - acc: 0.8722 - val_loss: 0.3276 - val_acc: 0.8495\n",
      "Epoch 13/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2756 - acc: 0.8734 - val_loss: 0.3340 - val_acc: 0.8529\n",
      "Epoch 14/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2735 - acc: 0.8740 - val_loss: 0.3307 - val_acc: 0.8514\n",
      "Epoch 15/200\n",
      "26048/26048 [==============================] - 0s - loss: 0.2722 - acc: 0.8747 - val_loss: 0.3308 - val_acc: 0.8506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3452c4ca20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "classfier = Sequential()\n",
    "\n",
    "#classfier.add(Dropout(0.1, input_shape=(106,)))\n",
    "classfier.add(Dense(106, kernel_initializer=\"uniform\", use_bias=True, activation=\"relu\", input_shape=(106,)))\n",
    "#classfier.add(Dropout(0.1))\n",
    "classfier.add(Dense(53, kernel_initializer=\"uniform\", use_bias=True, activation=\"relu\"))\n",
    "#classfier.add(Dropout(0.1))\n",
    "classfier.add(Dense(53, kernel_initializer=\"uniform\", use_bias=True, activation=\"relu\"))\n",
    "#classfier.add(Dropout(0.2))\n",
    "classfier.add(Dense(1, kernel_initializer=\"uniform\", use_bias=True, activation=\"sigmoid\"))\n",
    "\n",
    "classfier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "call = EarlyStopping(monitor = 'val_loss', min_delta=0, patience = 10)\n",
    "classfier.fit(X_train, y_train, validation_data=(X_val,y_val), batch_size=250, nb_epoch=200, callbacks=[call])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = []\n",
    "with open('../data/X_test') as f:\n",
    "    row = csv.reader(f, delimiter =\",\")\n",
    "    next(row,None)\n",
    "    for r in row:\n",
    "        x_test.append(list(map(float,r)))\n",
    "        \n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre = classfier.predict(x_test)\n",
    "pre = pre > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = []\n",
    "ans.append([\"id\", \"label\"])\n",
    "for i in range(pre.shape[0]):\n",
    "    ans.append([i+1,int(pre[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'test.csv'\n",
    "with open(filename,'w+') as f:\n",
    "    s = csv.writer(f,delimiter=',',lineterminator='\\n')\n",
    "    for i in range(len(ans)):\n",
    "        s.writerow(ans[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
