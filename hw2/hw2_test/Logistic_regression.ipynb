{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import argparse\n",
    "from math import log, floor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(train_data_path, train_label_path, test_data_path):\n",
    "    X_train = pd.read_csv(train_data_path, sep=',', header=0)\n",
    "    X_train = np.array(X_train.values)\n",
    "    Y_train = pd.read_csv(train_label_path, sep=',', header=0)\n",
    "    Y_train = np.array(Y_train.values)\n",
    "    X_test = pd.read_csv(test_data_path, sep=',', header=0)\n",
    "    X_test = np.array(X_test.values)\n",
    "\n",
    "    return (X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _shuffle(X, Y):\n",
    "    randomize = np.arange(len(X))\n",
    "    np.random.shuffle(randomize)\n",
    "    return (X[randomize], Y[randomize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(X_all, X_test):\n",
    "    # Feature normalization with train and test X\n",
    "    X_train_test = np.concatenate((X_all, X_test))\n",
    "    mu = (sum(X_train_test) / X_train_test.shape[0])\n",
    "    sigma = np.std(X_train_test, axis=0)\n",
    "    mu = np.tile(mu, (X_train_test.shape[0], 1))\n",
    "    sigma = np.tile(sigma, (X_train_test.shape[0], 1))\n",
    "    X_train_test_normed = (X_train_test - mu) / sigma\n",
    "\n",
    "    # Split to train, test again\n",
    "    X_all = X_train_test_normed[0:X_all.shape[0]]\n",
    "    X_test = X_train_test_normed[X_all.shape[0]:]\n",
    "    return X_all, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_valid_set(X_all, Y_all, percentage):\n",
    "    all_data_size = len(X_all)\n",
    "    valid_data_size = int(floor(all_data_size * percentage))\n",
    "\n",
    "    X_all, Y_all = _shuffle(X_all, Y_all)\n",
    "\n",
    "    X_train, Y_train = X_all[0:valid_data_size], Y_all[0:valid_data_size]\n",
    "    X_valid, Y_valid = X_all[valid_data_size:], Y_all[valid_data_size:]\n",
    "\n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1.0 + np.exp(-z))\n",
    "    return np.clip(res, 1e-8, 1-(1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid(w, b, X_valid, Y_valid):\n",
    "    valid_data_size = len(X_valid)\n",
    "\n",
    "    z = (np.dot(X_valid, np.transpose(w)) + b)\n",
    "    y = sigmoid(z)\n",
    "    y_ = np.around(y)\n",
    "    result = (np.squeeze(Y_valid) == y_)\n",
    "    print('Validation acc = %f' % (float(result.sum()) / valid_data_size))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_all, Y_all, save_dir):\n",
    "    # Split a 10%-validation set from the training set\n",
    "    valid_set_percentage = 0.2\n",
    "    X_train, Y_train, X_valid, Y_valid = split_valid_set(X_all, Y_all, valid_set_percentage)\n",
    "\n",
    "    # Initiallize parameter, hyperparameter\n",
    "    w = np.zeros((106,))\n",
    "    b = np.zeros((1,))\n",
    "    l_rate = 0.1\n",
    "    batch_size = 32\n",
    "    train_data_size = len(X_train)\n",
    "    step_num = int(floor(train_data_size / batch_size))\n",
    "    epoch_num = 2000\n",
    "    save_param_iter = 50\n",
    "\n",
    "    # Start training\n",
    "    total_loss = 0.0\n",
    "    for epoch in range(1, epoch_num):\n",
    "        # Do validation and parameter saving\n",
    "        if (epoch) % save_param_iter == 0:\n",
    "            print('=====Saving Param at epoch %d=====' % epoch)\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.mkdir(save_dir)\n",
    "            np.savetxt(os.path.join(save_dir, 'w'), w)\n",
    "            np.savetxt(os.path.join(save_dir, 'b'), [b,])\n",
    "            print('epoch avg loss = %f' % (total_loss / (float(save_param_iter) * train_data_size)))\n",
    "            total_loss = 0.0\n",
    "            valid(w, b, X_valid, Y_valid)\n",
    "\n",
    "        # Random shuffle\n",
    "        X_train, Y_train = _shuffle(X_train, Y_train)\n",
    "\n",
    "        # Train with batch\n",
    "        for idx in range(step_num):\n",
    "            X = X_train[idx*batch_size:(idx+1)*batch_size]\n",
    "            Y = Y_train[idx*batch_size:(idx+1)*batch_size]\n",
    "\n",
    "            z = np.dot(X, np.transpose(w)) + b\n",
    "            y = sigmoid(z)\n",
    "\n",
    "            cross_entropy = -1 * (np.dot(np.squeeze(Y), np.log(y)) + np.dot((1 - np.squeeze(Y)), np.log(1 - y)))\n",
    "            total_loss += cross_entropy\n",
    "\n",
    "            w_grad = np.mean(-1 * X * (np.squeeze(Y) - y).reshape((batch_size,1)), axis=0)\n",
    "            b_grad = np.mean(-1 * (np.squeeze(Y) - y))\n",
    "\n",
    "            # SGD updating parameters\n",
    "            w = w - l_rate * w_grad\n",
    "            b = b - l_rate * b_grad\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer(X_test, save_dir, output_dir):\n",
    "    test_data_size = len(X_test)\n",
    "\n",
    "    # Load parameters\n",
    "    print('=====Loading Param from %s=====' % save_dir)\n",
    "    w = np.loadtxt(os.path.join(save_dir, 'w'))\n",
    "    b = np.loadtxt(os.path.join(save_dir, 'b'))\n",
    "\n",
    "    # predict\n",
    "    z = (np.dot(X_test, np.transpose(w)) + b)\n",
    "    y = sigmoid(z)\n",
    "    y_ = np.around(y)\n",
    "\n",
    "    print('=====Write output to %s =====' % output_dir)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    output_path = os.path.join(output_dir, 'log_prediction.csv')\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('id,label\\n')\n",
    "        for i, v in  enumerate(y_):\n",
    "            f.write('%d,%d\\n' %(i+1, v))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Saving Param at epoch 50=====\n",
      "epoch avg loss = 0.322463\n",
      "Validation acc = 0.846712\n",
      "=====Saving Param at epoch 100=====\n",
      "epoch avg loss = 0.326520\n",
      "Validation acc = 0.846827\n",
      "=====Saving Param at epoch 150=====\n",
      "epoch avg loss = 0.326923\n",
      "Validation acc = 0.844908\n",
      "=====Saving Param at epoch 200=====\n",
      "epoch avg loss = 0.326777\n",
      "Validation acc = 0.846904\n",
      "=====Saving Param at epoch 250=====\n",
      "epoch avg loss = 0.326782\n",
      "Validation acc = 0.847288\n",
      "=====Saving Param at epoch 300=====\n",
      "epoch avg loss = 0.326688\n",
      "Validation acc = 0.847249\n",
      "=====Saving Param at epoch 350=====\n",
      "epoch avg loss = 0.326666\n",
      "Validation acc = 0.844332\n",
      "=====Saving Param at epoch 400=====\n",
      "epoch avg loss = 0.326696\n",
      "Validation acc = 0.847557\n",
      "=====Saving Param at epoch 450=====\n",
      "epoch avg loss = 0.326767\n",
      "Validation acc = 0.847595\n",
      "=====Saving Param at epoch 500=====\n",
      "epoch avg loss = 0.326655\n",
      "Validation acc = 0.848209\n",
      "=====Saving Param at epoch 550=====\n",
      "epoch avg loss = 0.326641\n",
      "Validation acc = 0.846981\n",
      "=====Saving Param at epoch 600=====\n",
      "epoch avg loss = 0.326682\n",
      "Validation acc = 0.846789\n",
      "=====Saving Param at epoch 650=====\n",
      "epoch avg loss = 0.326639\n",
      "Validation acc = 0.846443\n",
      "=====Saving Param at epoch 700=====\n",
      "epoch avg loss = 0.326777\n",
      "Validation acc = 0.845292\n",
      "=====Saving Param at epoch 750=====\n",
      "epoch avg loss = 0.326647\n",
      "Validation acc = 0.846328\n",
      "=====Saving Param at epoch 800=====\n",
      "epoch avg loss = 0.326895\n",
      "Validation acc = 0.846558\n",
      "=====Saving Param at epoch 850=====\n",
      "epoch avg loss = 0.326832\n",
      "Validation acc = 0.845867\n",
      "=====Saving Param at epoch 900=====\n",
      "epoch avg loss = 0.326875\n",
      "Validation acc = 0.845714\n",
      "=====Saving Param at epoch 950=====\n",
      "epoch avg loss = 0.326670\n",
      "Validation acc = 0.847787\n",
      "=====Saving Param at epoch 1000=====\n",
      "epoch avg loss = 0.326711\n",
      "Validation acc = 0.848094\n",
      "=====Saving Param at epoch 1050=====\n",
      "epoch avg loss = 0.326793\n",
      "Validation acc = 0.847211\n",
      "=====Saving Param at epoch 1100=====\n",
      "epoch avg loss = 0.326676\n",
      "Validation acc = 0.847365\n",
      "=====Saving Param at epoch 1150=====\n",
      "epoch avg loss = 0.327056\n",
      "Validation acc = 0.847518\n",
      "=====Saving Param at epoch 1200=====\n",
      "epoch avg loss = 0.326822\n",
      "Validation acc = 0.846981\n",
      "=====Saving Param at epoch 1250=====\n",
      "epoch avg loss = 0.326827\n",
      "Validation acc = 0.846597\n",
      "=====Saving Param at epoch 1300=====\n",
      "epoch avg loss = 0.326655\n",
      "Validation acc = 0.844716\n",
      "=====Saving Param at epoch 1350=====\n",
      "epoch avg loss = 0.326696\n",
      "Validation acc = 0.845599\n",
      "=====Saving Param at epoch 1400=====\n",
      "epoch avg loss = 0.326798\n",
      "Validation acc = 0.845023\n",
      "=====Saving Param at epoch 1450=====\n",
      "epoch avg loss = 0.326916\n",
      "Validation acc = 0.846290\n",
      "=====Saving Param at epoch 1500=====\n",
      "epoch avg loss = 0.326819\n",
      "Validation acc = 0.846981\n",
      "=====Saving Param at epoch 1550=====\n",
      "epoch avg loss = 0.326722\n",
      "Validation acc = 0.848862\n",
      "=====Saving Param at epoch 1600=====\n",
      "epoch avg loss = 0.327005\n",
      "Validation acc = 0.846213\n",
      "=====Saving Param at epoch 1650=====\n",
      "epoch avg loss = 0.326749\n",
      "Validation acc = 0.847557\n",
      "=====Saving Param at epoch 1700=====\n",
      "epoch avg loss = 0.326714\n",
      "Validation acc = 0.846328\n",
      "=====Saving Param at epoch 1750=====\n",
      "epoch avg loss = 0.326919\n",
      "Validation acc = 0.846290\n",
      "=====Saving Param at epoch 1800=====\n",
      "epoch avg loss = 0.326698\n",
      "Validation acc = 0.845445\n",
      "=====Saving Param at epoch 1850=====\n",
      "epoch avg loss = 0.326718\n",
      "Validation acc = 0.847326\n",
      "=====Saving Param at epoch 1900=====\n",
      "epoch avg loss = 0.326747\n",
      "Validation acc = 0.845791\n",
      "=====Saving Param at epoch 1950=====\n",
      "epoch avg loss = 0.326889\n",
      "Validation acc = 0.846981\n"
     ]
    }
   ],
   "source": [
    "X_all, Y_all, X_test = load_data('X_train', 'Y_train', 'X_test')\n",
    "X_all, X_test = normalize(X_all, X_test)\n",
    "train(X_all, Y_all, 'logistic_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Loading Param from logistic_params=====\n",
      "=====Write output to logistic_output =====\n"
     ]
    }
   ],
   "source": [
    "infer(X_test, 'logistic_params', 'logistic_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
